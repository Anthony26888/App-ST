const express = require("express");
const router = express.Router();
const fetch = require("node-fetch");

// Ollama API configuration
const OLLAMA_API_URL = "http://localhost:11434/api/chat";
const SYSTEM_PROMPT = `Báº¡n lÃ  trá»£ lÃ½ phÃ¢n tÃ­ch ERP SiÃªu Thuáº­t.

QUAN TRá»ŒNG: 
- Tráº£ lá»i báº±ng vÄƒn báº£n tá»± nhiÃªn, KHÃ”NG tráº£ lá»i dÆ°á»›i dáº¡ng JSON
- HoÃ n toÃ n nÃ³i tiáº¿ng Viá»‡t
- Tráº£ lá»i ngáº¯n gá»n, dá»… hiá»ƒu

YÃªu cáº§u:
1. So sÃ¡nh trend giá»¯a hÃ´m nay vÃ  hÃ´m qua (PO, sáº£n pháº©m, completed, defects)
2. Highlight KPI quan trá»ng vÃ  cáº£nh bÃ¡o (vÃ­ dá»¥ sáº£n pháº©m lá»—i, tá»· lá»‡ hoÃ n thÃ nh giáº£m)
3. TÃ³m táº¯t ngáº¯n gá»n, bullet points, dá»… Ä‘á»c cho dashboard
4. Chá»‰ phÃ¢n tÃ­ch dá»¯ liá»‡u cÃ³ trong report, khÃ´ng suy Ä‘oÃ¡n thÃªm
5. KHÃ”NG bao giá» tráº£ lá»i dÆ°á»›i dáº¡ng JSON hoáº·c code`;

// Store io instance
let io;

// Store analysis context for chat sessions
const analysisContexts = new Map(); // socketId -> { summaryData, conversationHistory }

// Function to set io instance
const setIO = (socketIO) => {
  io = socketIO;
};

// POST /api/ai/analyze-summary
router.post("/analyze-summary", async (req, res) => {
  const { summaryData, socketId } = req.body;

  if (!summaryData || !socketId) {
    return res.status(400).json({ error: "Missing summaryData or socketId" });
  }

  if (!io) {
    return res.status(500).json({ error: "Socket.IO not initialized" });
  }

  try {
    // Create concise, focused prompt for faster analysis
    let userMessage = `ðŸ“Š BÃO CÃO Sáº¢N XUáº¤T NGÃ€Y ${summaryData.date}

â–ªï¸ Tá»•ng sá»‘ PO: ${summaryData.stats?.totalPO || 0}
â–ªï¸ Tá»•ng háº¡ng má»¥c: ${summaryData.stats?.totalCategory || 0}
â–ªï¸ HoÃ n thÃ nh: ${summaryData.stats?.completed || 0}/${summaryData.stats?.totalCategory || 0}
â–ªï¸ Äang thá»±c hiá»‡n: ${summaryData.stats?.inProgress || 0}
â–ªï¸ Tá»· lá»‡ Pass: ${summaryData.stats?.passRate || 0}%
â–ªï¸ Sáº£n pháº©m Pass: ${summaryData.stats?.totalPass || 0}
â–ªï¸ Sáº£n pháº©m Fail: ${summaryData.stats?.totalFail || 0}`;

    // Add comparison if available
    if (summaryData.comparison) {
      const trend = summaryData.comparison;
      const poChange = (summaryData.stats?.totalPO || 0) - trend.yesterdayPO;
      const categoryChange = (summaryData.stats?.totalCategory || 0) - trend.yesterdayCategory;
      
      userMessage += `\n\nðŸ“ˆ SO SÃNH Vá»šI NGÃ€Y HÃ”M QUA:
â–ªï¸ Sá»‘ PO: ${trend.yesterdayPO} â†’ ${summaryData.stats?.totalPO || 0} (${poChange >= 0 ? '+' : ''}${poChange}, ${trend.poTrend >= 0 ? '+' : ''}${trend.poTrend}%)
â–ªï¸ Háº¡ng má»¥c: ${trend.yesterdayCategory} â†’ ${summaryData.stats?.totalCategory || 0} (${categoryChange >= 0 ? '+' : ''}${categoryChange}, ${trend.categoryTrend >= 0 ? '+' : ''}${trend.categoryTrend}%)`;
    }

    // Add process breakdown if available
    if (summaryData.processes && Object.keys(summaryData.processes).length > 0) {
      userMessage += `\n\nðŸ”§ CHI TIáº¾T CÃC CÃ”NG ÄOáº N:`;
      Object.entries(summaryData.processes).forEach(([processName, data]) => {
        const total = data.total || 0;
        const completed = data.completed || 0;
        const rate = total > 0 ? Math.round((completed / total) * 100) : 0;
        const pass = data.totalOK || 0;
        const fail = data.totalError || 0;
        const passRate = (pass + fail) > 0 ? Math.round((pass / (pass + fail)) * 100) : 0;
        
        userMessage += `\nâ–ªï¸ ${processName}: ${completed}/${total} háº¡ng má»¥c (${rate}%) | Pass: ${pass}, Fail: ${fail} (${passRate}%)`;
      });
    }

    // Add top errors if any
    if (summaryData.topErrors && summaryData.topErrors.length > 0) {
      userMessage += `\n\nâŒ TOP Lá»–I NHIá»€U NHáº¤T:\n${summaryData.topErrors.map(e => `â–ªï¸ ${e}`).join('\n')}`;
    }

    userMessage += `\n\nðŸ’¡ HÃ£y Ä‘Æ°a ra nháº­n xÃ©t ngáº¯n gá»n (3-5 cÃ¢u) vá»:
1. Hiá»‡u suáº¥t sáº£n xuáº¥t hÃ´m nay
2. Xu hÆ°á»›ng so vá»›i hÃ´m qua (tÄƒng/giáº£m, tá»‘t/xáº¥u)
3. Váº¥n Ä‘á» cáº§n chÃº Ã½ (náº¿u cÃ³)`;

    // Call Ollama API
    const response = await fetch(OLLAMA_API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: "llama3:latest",
        messages: [
          { role: "system", content: SYSTEM_PROMPT },
          { role: "user", content: userMessage }
        ],
        stream: true,
        options: {
          temperature: 0.7,
          num_predict: 200  // Limit response length for speed
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.statusText}`);
    }

    // Stream response to client via Socket.IO
    const reader = response.body;
    reader.on("data", (chunk) => {
      const lines = chunk.toString().split("\n").filter(line => line.trim());
      
      for (const line of lines) {
        try {
          const json = JSON.parse(line);
          if (json.message && json.message.content) {
            io.to(socketId).emit("ai-stream", json.message.content);
          }
          
          if (json.done) {
            io.to(socketId).emit("ai-done");
          }
        } catch (e) {
          console.error("Error parsing JSON:", e);
        }
      }
    });

    reader.on("error", (error) => {
      console.error("Stream error:", error);
      io.to(socketId).emit("ai-error", "Lá»—i khi nháº­n dá»¯ liá»‡u tá»« AI");
    });

    reader.on("end", () => {
      io.to(socketId).emit("ai-done");
      
      // Store context for chat
      analysisContexts.set(socketId, {
        summaryData,
        conversationHistory: [],
        timestamp: Date.now()
      });
    });

    res.json({ message: "Analysis started" });
  } catch (error) {
    console.error("AI Analysis Error:", error);
    io.to(socketId).emit("ai-error", error.message);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/ai/compare-summary
router.post("/compare-summary", async (req, res) => {
  const { todayData, yesterdayData, socketId } = req.body;

  if (!todayData || !yesterdayData || !socketId) {
    return res.status(400).json({ error: "Missing todayData, yesterdayData or socketId" });
  }

  if (!io) {
    return res.status(500).json({ error: "Socket.IO not initialized" });
  }

  try {
    // Format comparison data for AI analysis
    const comparisonPrompt = `So sÃ¡nh dá»¯ liá»‡u sáº£n xuáº¥t giá»¯a 2 ngÃ y:

ðŸ“… NGÃ€Y HÃ”M QUA (${yesterdayData.date}):
${JSON.stringify(yesterdayData, null, 2)}

ðŸ“… NGÃ€Y HÃ”M NAY (${todayData.date}):
${JSON.stringify(todayData, null, 2)}

HÃ£y phÃ¢n tÃ­ch:
1. Sá»± khÃ¡c biá»‡t vá» sá»‘ lÆ°á»£ng PO, háº¡ng má»¥c, tá»· lá»‡ hoÃ n thÃ nh
2. Xu hÆ°á»›ng tÄƒng/giáº£m (tá»‘t hay xáº¥u)
3. CÃ¡c váº¥n Ä‘á» vá» lá»—i sáº£n xuáº¥t
4. Äá» xuáº¥t cáº£i thiá»‡n cá»¥ thá»ƒ`;

    // Call Ollama API
    const response = await fetch(OLLAMA_API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: "llama3:latest",
        messages: [
          { role: "system", content: SYSTEM_PROMPT },
          { role: "user", content: comparisonPrompt }
        ],
        stream: true
      })
    });

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.statusText}`);
    }

    // Stream response to client via Socket.IO
    const reader = response.body;
    reader.on("data", (chunk) => {
      const lines = chunk.toString().split("\n").filter(line => line.trim());
      
      for (const line of lines) {
        try {
          const json = JSON.parse(line);
          if (json.message && json.message.content) {
            io.to(socketId).emit("ai-stream", json.message.content);
          }
          
          if (json.done) {
            io.to(socketId).emit("ai-done");
          }
        } catch (e) {
          console.error("Error parsing JSON:", e);
        }
      }
    });

    reader.on("error", (error) => {
      console.error("Stream error:", error);
      io.to(socketId).emit("ai-error", "Lá»—i khi nháº­n dá»¯ liá»‡u tá»« AI");
    });

    reader.on("end", () => {
      io.to(socketId).emit("ai-done");
    });

    res.json({ message: "Comparison started" });
  } catch (error) {
    console.error("AI Comparison Error:", error);
    io.to(socketId).emit("ai-error", error.message);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/ai/chat - Handle follow-up questions
router.post("/chat", async (req, res) => {
  const { question, socketId } = req.body;

  if (!question || !socketId) {
    return res.status(400).json({ error: "Missing question or socketId" });
  }

  if (!io) {
    return res.status(500).json({ error: "Socket.IO not initialized" });
  }

  // Get stored context
  const context = analysisContexts.get(socketId);
  if (!context) {
    return res.status(400).json({ error: "No analysis context found. Please run analysis first." });
  }

  try {
    // Build conversation history
    const messages = [
      { role: "system", content: SYSTEM_PROMPT },
      // Add original analysis context
      { 
        role: "system", 
        content: `Dá»¯ liá»‡u bÃ¡o cÃ¡o Ä‘Ã£ phÃ¢n tÃ­ch (chá»‰ Ä‘á»ƒ tham kháº£o):\n${JSON.stringify(context.summaryData, null, 2)}\n\nHÃ£y tráº£ lá»i cÃ¢u há»i báº±ng VÄ‚N Báº¢N Tá»° NHIÃŠN, KHÃ”NG dÃ¹ng JSON. Tráº£ lá»i ngáº¯n gá»n, dá»… hiá»ƒu báº±ng tiáº¿ng Viá»‡t.` 
      },
      // Add conversation history
      ...context.conversationHistory,
      // Add current question
      { role: "user", content: question }
    ];

    // Call Ollama API
    const response = await fetch(OLLAMA_API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model: "llama3:latest",
        messages: messages,
        stream: true,
        options: {
          temperature: 0.7,
          num_predict: 300
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.statusText}`);
    }

    let fullResponse = "";

    // Stream response to client via Socket.IO
    const reader = response.body;
    reader.on("data", (chunk) => {
      const lines = chunk.toString().split("\n").filter(line => line.trim());
      
      for (const line of lines) {
        try {
          const json = JSON.parse(line);
          if (json.message && json.message.content) {
            fullResponse += json.message.content;
            io.to(socketId).emit("ai-chat-stream", json.message.content);
          }
          
          if (json.done) {
            io.to(socketId).emit("ai-chat-done");
            
            // Update conversation history
            context.conversationHistory.push(
              { role: "user", content: question },
              { role: "assistant", content: fullResponse }
            );
            
            // Keep only last 10 messages to avoid context getting too long
            if (context.conversationHistory.length > 20) {
              context.conversationHistory = context.conversationHistory.slice(-20);
            }
          }
        } catch (e) {
          console.error("Error parsing JSON:", e);
        }
      }
    });

    reader.on("error", (error) => {
      console.error("Stream error:", error);
      io.to(socketId).emit("ai-chat-error", "Lá»—i khi nháº­n dá»¯ liá»‡u tá»« AI");
    });

    reader.on("end", () => {
      io.to(socketId).emit("ai-chat-done");
    });

    res.json({ message: "Chat started" });
  } catch (error) {
    console.error("AI Chat Error:", error);
    io.to(socketId).emit("ai-chat-error", error.message);
    res.status(500).json({ error: error.message });
  }
});

module.exports = { router, setIO };
